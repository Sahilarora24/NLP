{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wbjt03L5275WrD4EHmfgmDsKyiE3VfSE",
      "authorship_tag": "ABX9TyNi392kf3aIyXwXQsRrHaM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahilarora24/NLP/blob/main/Module%201/Word2Vec%26AvgWord2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VBR6yrp65h-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be64c8e-5700-49b7-8d14-7ff67d158d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Code with Bag of Words*"
      ],
      "metadata": {
        "id": "1nSHvt88MCn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = pd.read_csv(\"/content/drive/MyDrive/data/spam.csv\",encoding='latin1')"
      ],
      "metadata": {
        "id": "pct6XzYb_YsN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace= True)"
      ],
      "metadata": {
        "id": "OakZzvgQAJE0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.rename(columns={'v1': 'label', 'v2': 'message'}, inplace=True)\n",
        "messages.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z6LZxzofASQC",
        "outputId": "bb85d8ad-f38b-403b-ea5e-5271810b9c5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label                                            message\n",
              "1658  spam  RGENT! This is the 2nd attempt to contact U!U ...\n",
              "2800   ham                      Depends on where u going lor.\n",
              "3076   ham            There is no sense in my foot and penis.\n",
              "2349   ham    Yar else i'll thk of all sorts of funny things.\n",
              "3692   ham  I was about to do it when i texted. I finished..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4633d4fb-5889-447d-a0cd-fd35b13436e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1658</th>\n",
              "      <td>spam</td>\n",
              "      <td>RGENT! This is the 2nd attempt to contact U!U ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2800</th>\n",
              "      <td>ham</td>\n",
              "      <td>Depends on where u going lor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>ham</td>\n",
              "      <td>There is no sense in my foot and penis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yar else i'll thk of all sorts of funny things.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3692</th>\n",
              "      <td>ham</td>\n",
              "      <td>I was about to do it when i texted. I finished...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4633d4fb-5889-447d-a0cd-fd35b13436e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4633d4fb-5889-447d-a0cd-fd35b13436e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4633d4fb-5889-447d-a0cd-fd35b13436e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b211cca5-86b1-4e6f-854e-62883ba7a2ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b211cca5-86b1-4e6f-854e-62883ba7a2ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b211cca5-86b1-4e6f-854e-62883ba7a2ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"messages\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ham\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Depends on where u going lor.\",\n          \"I was about to do it when i texted. I finished a long time ago and showered and er'ything!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages['message'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1qbc4E0vAqeM",
        "outputId": "1fcc0a67-34dc-4a75-adb3-488be035b407"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ok lar... Joking wif u oni...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Cleaning and Pre processing"
      ],
      "metadata": {
        "id": "b9FqbnMbVuh5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqEhXNduYsZl",
        "outputId": "0e4fa215-1670-4048-ccb7-3286188bea6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps=PorterStemmer()"
      ],
      "metadata": {
        "id": "r7Q80wkVa6Re"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "\n",
        "# Loop through each message in the dataset\n",
        "for i in range(0, len(messages)):\n",
        "\n",
        "    # Step 1: Remove all characters except alphabets (replace them with space)\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
        "\n",
        "    # Step 2: Convert the entire message to lowercase\n",
        "    review = review.lower()\n",
        "\n",
        "    # Step 3: Split the message into individual words (tokens)\n",
        "    review = review.split()\n",
        "\n",
        "    # Step 4: Remove stopwords (like 'the', 'is', 'and') and apply stemming\n",
        "    # Stemming reduces words to their root form (e.g., \"running\" ‚Üí \"run\")\n",
        "    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
        "\n",
        "    # Step 5: Join the processed words back into a single string\n",
        "    review = ' '.join(review)\n",
        "\n",
        "    # Step 6: Add the cleaned message to the corpus\n",
        "    corpus.append(review)\n"
      ],
      "metadata": {
        "id": "kJWC1HiubS_C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X7YQxuQccJcS",
        "outputId": "cf808640-3017-4f1f-bdbf-5ac46d6e5693"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ok lar joke wif u oni'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer is a tool from sklearn that converts text into numbers using the Bag of Words (BoW) model.\n",
        "#\n",
        "# It turns your text data (the corpus) into a big table (called a document-term matrix) where:\n",
        "# - Rows = each message\n",
        "# - Columns = each unique word (from the entire corpus)\n",
        "# - Values = how often that word appears in that message\n",
        "#\n",
        "# Parameters explained:\n",
        "# max_features=2500\n",
        "# - This tells the vectorizer to keep only the top 2,500 most frequent words from the entire corpus.\n",
        "# - If your data has 10,000 unique words, this will cut it down to the most important 2,500 based on frequency.\n",
        "# - Helps reduce memory usage and noise.\n",
        "#\n",
        "# binary=True\n",
        "# - Instead of counting how many times a word appears, it just marks:\n",
        "#     1 ‚Üí if the word exists in the message\n",
        "#     0 ‚Üí if it doesn't\n",
        "# - This is useful when you only care whether a word appears, not how many times.\n",
        "#\n",
        "# Example:\n",
        "# corpus = [\"i love machine learning\", \"machine learning is fun\"]\n",
        "# Vocabulary (words): ['fun', 'is', 'learning', 'love', 'machine']\n",
        "#\n",
        "# Then the matrix X will look like:\n",
        "#\n",
        "# Message                          fun  is  learning  love  machine\n",
        "# \"i love machine learning\"        0    0     1        1      1\n",
        "# \"machine learning is fun\"        1    1     1        0      1\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=2500,binary=True)\n",
        "X=cv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "2RHauwxbeRtK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS9ENXnhgDjI",
        "outputId": "2470d457-3b10-40ba-b062-0f3d0f948737"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJEX_wCjgRIE",
        "outputId": "20bcc00f-2fc9-4076-b30c-8416175772db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the text labels (like 'ham' and 'spam') into numeric format using one-hot encoding\n",
        "# For example: 'ham' ‚Üí [1, 0], 'spam' ‚Üí [0, 1]\n",
        "y = messages['label'].map({'ham': 0, 'spam': 1})"
      ],
      "metadata": {
        "id": "h8SqgcFFhq8M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "wtIYk8NEdYsT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the feature matrix (X) and labels (y) into:\n",
        "# - 80% training data (X_train, y_train)\n",
        "# - 20% testing data (X_test, y_test)\n",
        "# random_state=42 ensures the split is reproducible\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "fcGRaSVedcGw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Create the model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Step 2: Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P7aE_jKd_9t",
        "outputId": "f1953b56-68b7-4045-bc1c-8734d5f14fad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.979372197309417\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       965\n",
            "           1       0.93      0.92      0.92       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.95      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "Confusion Matrix:\n",
            " [[954  11]\n",
            " [ 12 138]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Code with TF-IDF*"
      ],
      "metadata": {
        "id": "VOtJFnp-x8iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=2500)\n",
        "X = tfidf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "nN5D8Wt9gHeo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the text labels (like 'ham' and 'spam') into numeric format using one-hot encoding\n",
        "# For example: 'ham' ‚Üí [1, 0], 'spam' ‚Üí [0, 1]\n",
        "y = messages['label'].map({'ham': 0, 'spam': 1})"
      ],
      "metadata": {
        "id": "hBRsuWOJxtwr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the feature matrix (X) and labels (y) into:\n",
        "# - 80% training data (X_train, y_train)\n",
        "# - 20% testing data (X_test, y_test)\n",
        "# random_state=42 ensures the split is reproducible\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "_2i63IJWx1-d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Create the model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Step 2: Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUx4_lZDx3Zm",
        "outputId": "7e8b7088-f719-4fa9-c4c3-ca9aa419c0c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97847533632287\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       1.00      0.84      0.91       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.92      0.95      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 24 126]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Changing Model and Try*"
      ],
      "metadata": {
        "id": "2BHvsxr3zGbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Step 1: Create the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Step 2: Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMWzR94mx4fq",
        "outputId": "0d55a774-e13e-4887-9b00-858609c69d47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9802690582959641\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       0.99      0.86      0.92       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "Confusion Matrix:\n",
            " [[964   1]\n",
            " [ 21 129]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Word2Vec Implementation*"
      ],
      "metadata": {
        "id": "4LEEFeMj05Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a neural embedding model that converts words into dense vector representations that capture meaning. Unlike BoW or TF-IDF (which only count word occurrences), Word2Vec understands semantic relationships for example, the vectors for \"king\" and \"queen\" will be close together.\n",
        "\n"
      ],
      "metadata": {
        "id": "XConHvu41zIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KUIzS7_U1w_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EeEkDK610uE",
        "outputId": "9d667f51-2166-4518-f638-10e2e2fa5fd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train Word2Vec model on the corpus\n",
        "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQmLA5qT1-RG",
        "outputId": "a52e3747-7ef2-4976-d901-67372abf6254"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector_size=100\n",
        "# Each word will be represented as a 100-dimensional vector.\n",
        "# Example: \"king\" ‚Üí [0.25, -0.13, 0.08, ..., 0.91]  # total 100 values\n",
        "# Similar words like \"king\" and \"queen\" will have similar vectors.\n",
        "# Unrelated words like \"king\" and \"banana\" will have very different vectors.\n",
        "# ‚úÖ Higher vector_size can capture more meaning, but needs more data.\n",
        "\n",
        "# window=5\n",
        "# This defines the context window size ‚Äî how many words before and after the target word are considered.\n",
        "# Example with window=2: Sentence = \"I love natural language processing\"\n",
        "# For the center word \"natural\", the context would be: [\"love\", \"language\"]\n",
        "# ‚úÖ Larger window ‚Üí captures broader meaning (semantics)\n",
        "# ‚úÖ Smaller window ‚Üí captures nearby structure (syntax)\n",
        "\n",
        "# min_count=1\n",
        "# Only include words that appear at least this many times in the corpus.\n",
        "# Example corpus: [\"apple banana apple\", \"banana orange\", \"grape\"]\n",
        "# Word counts: apple=2, banana=2, orange=1, grape=1\n",
        "# ‚úîÔ∏è If min_count=1 ‚Üí includes all: [\"apple\", \"banana\", \"orange\", \"grape\"]\n",
        "# ‚ùå If min_count=2 ‚Üí excludes rare words: [\"apple\", \"banana\"]\n",
        "# ‚úÖ Set to 1 for small datasets to keep all words.\n",
        "# ‚úÖ Set higher (e.g. 5) for large datasets to remove noise.\n"
      ],
      "metadata": {
        "id": "tZNvfroj2raC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ‚úÖ Function: Convert a sentence (list of words) into a single vector\n",
        "def get_sentence_vector(words, model):\n",
        "    # Get vector for each word if it's present in the model's vocabulary\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "\n",
        "    # üîÅ Example:\n",
        "    # Let's say words = [\"king\", \"rules\", \"dragon\"]\n",
        "    # If all are in the model:\n",
        "    # model.wv[\"king\"] = [0.2, 0.5, ..., 0.8]  # 100-dim\n",
        "    # model.wv[\"rules\"] = [0.1, 0.4, ..., 0.6]\n",
        "    # model.wv[\"dragon\"] = [0.3, 0.2, ..., 0.9]\n",
        "    # ‚û° vectors = [vec_king, vec_rules, vec_dragon]\n",
        "\n",
        "    # Return the average of all word vectors ‚Üí sentence vector\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "# ‚úÖ Convert the entire corpus (list of tokenized sentences) to sentence vectors\n",
        "# Each sentence becomes a single 100-dim vector (if vector_size=100)\n",
        "\n",
        "# üí¨ Example corpus:\n",
        "# corpus = [[\"i\", \"love\", \"nlp\"], [\"king\", \"rules\", \"kingdom\"], [\"dragon\", \"queen\"]]\n",
        "\n",
        "# For each sentence, call get_sentence_vector ‚Üí average word vectors ‚Üí 1 vector per sentence\n",
        "X = np.array([get_sentence_vector(msg, model) for msg in corpus])\n",
        "\n",
        "# üîÅ Example output:\n",
        "# X.shape = (3, 100)  # 3 sentences, each represented by a 100-dim vector\n"
      ],
      "metadata": {
        "id": "cSZ4zpmK35KL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(messages['label'])['spam']  # 1 if spam, 0 if ham\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-T4xq8pf4EW3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tli0CC0t4GG1",
        "outputId": "32ea53c5-6bc3-4c48-b740-404a87e3b97f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8681614349775785\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93       965\n",
            "        True       0.64      0.05      0.09       150\n",
            "\n",
            "    accuracy                           0.87      1115\n",
            "   macro avg       0.75      0.52      0.51      1115\n",
            "weighted avg       0.84      0.87      0.82      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwXLHEYX4HgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}